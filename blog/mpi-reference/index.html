<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- JS for KaTeX -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
    <title>茨月的博客 | MPI 入门笔记</title>
    
    <link rel="stylesheet" href="https://blog.zcy.moe/style.css?h=05ce8a9f27c3f6647cbb">
    
</head>
<body>
    
<header class="space">
    
        <a href="https:&#x2F;&#x2F;blog.zcy.moe">&LeftArrow; Home</a>
    
</header>

    
<main>
    <h1>MPI 入门笔记</h1>

    
    <div class="post-meta">











<span title="2022-03-01 01:04:44 +0000">March 1, 2022</span>&nbsp;·&nbsp;茨月
</div>
    

    <div class="space"></div>
    <p>周二的高性能计算导论课上提到了 MPI，小作业里也用到了，但是代码没太看懂。于是寻找了一份 <a href="https://mpitutorial.com/tutorials/mpi-introduction/zh_cn/">MPI 的教程</a>，中文翻译质量不错但必要时还是得看英文。</p>
<span id="continue-reading"></span><h2 id="basic-facts">Basic Facts</h2>
<ul>
<li>
<p>MPI 是 Message Passing Interface 的简称</p>
</li>
<li>
<p>MPI 是一套标准，而实际的实现有许多</p>
<ul>
<li>包括但不限于 OpenMPI（conv 集群上使用的）和 MPICH（教程中使用的）</li>
</ul>
</li>
<li>
<p>MPI 为包括 Fortran77, C, Fortran90 和 C++ 在内的一系列编程语言提供了并行函数库</p>
</li>
<li>
<p>MPI 是进程 (process) 级并行，process 间内存不共享，与线程 (thread) 级并行不同</p>
</li>
</ul>
<h2 id="jian-dan-shi-yong-zhi-nan">简单使用指南</h2>
<h3 id="ji-ben-yao-qiu">基本要求</h3>
<ul>
<li>
<p>MPI 程序入口处应当调用 <code>MPI_Init(int* argc, char*** argv)</code> 函数，实际上两个参数可以都填 <code>NULL</code>。</p>
</li>
<li>
<p>MPI 程序结束前应当调用 <code>MPI_Finalize()</code> 函数</p>
</li>
</ul>
<h3 id="jin-cheng-jian-dian-dui-dian-tong-xin">进程间点对点通信</h3>
<ul>
<li>
<p>使用 <code>MPI_Comm_size(MPI_COMM_WORLD, &amp;world_size)</code> 来获取总进程数，保存在 <code>world_size</code> 中</p>
</li>
<li>
<p>使用 <code>MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank)</code> 来获取自己的进程编号，保存在 <code>world_rank</code> 中</p>
</li>
<li>
<p>使用 <code>MPI_Send(const void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm)</code> 来从一个 process 将数据发送到另一个 process</p>
<ul>
<li>buf 是待发送缓冲区</li>
<li>count 是发送数据数目</li>
<li>datatype 是数据类型，MPI 内部自己的枚举类，与 C 原生类型存在对应</li>
<li>dest 是目标 process 编号</li>
<li>tag 是编号，只有 tag 对应的消息才会被接收</li>
<li>comm 是组通讯器</li>
</ul>
</li>
<li>
<p>使用 <code>MPI_Recv(void *buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Status *status)</code> 来接收另一个 process 发来的数据</p>
<ul>
<li>buf 是接收用缓冲区</li>
<li>count 是最大接收数据数目
<ul>
<li>可以接收不超过这个数目的数据，如果超过会报错</li>
</ul>
</li>
<li>datatype 是数据类型</li>
<li>source 是源 process 编号
<ul>
<li>可以用 <code>MPI_ANY_SOURCE</code> 来接收所有源的消息</li>
</ul>
</li>
<li>tag 是编号，只有 tag 对应的消息才会被接收
<ul>
<li>可以用 <code>MPI_ANY_TAG</code> 来接收所有任意 tag 的消息</li>
</ul>
</li>
<li>comm 是组通讯器</li>
<li>status 是一个指向 <code>MPI_Status</code> 结构体的指针，这次接收的更多信息会保存在这个结构体里
<ul>
<li>可以用 <code>MPI_STATUS_IGNORE</code> 来丢弃这个东西</li>
</ul>
</li>
</ul>
</li>
<li>
<p><code>MPI_Send</code> 和 <code>MPI_Recv</code> 是阻塞的，在一次发送 / 接收完成前不会继续向下执行</p>
</li>
<li>
<p>如果要发送自定义类型</p>
<ul>
<li>将缓冲区强转 <code>void *</code></li>
<li><code>count</code> 填个数 * <code>sizeof(MyType)</code></li>
<li><code>datatype</code> 填 <code>MPI_BYTE</code></li>
</ul>
</li>
<li>
<p><code>MPI_Status</code> 结构体中记录了这些东西</p>
<ul>
<li>发送端的进程编号</li>
<li>消息的 tag</li>
<li>消息的长度（在指定类型后，元素个数也就可以知道了）</li>
</ul>
</li>
<li>
<p>使用 <code>MPI_Get_count(MPI_Status* status, MPI_Datatype datatype, int* count)</code> 来得到消息中的实际元素个数。</p>
</li>
<li>
<p>使用 <code>MPI_Probe(int source, int tag, MPI_Comm comm, MPI_Status* status)</code> 来在不接收的情况下得到 <code>MPI_Status</code>。</p>
<ul>
<li>如果不能确切知道实际待接收的元素个数，可以先 <code>MPI_Probe</code> 拿到 <code>status</code>，用 <code>MPI_Get_count</code> 算出个数，最后再 <code>MPI_Recv</code>。此时就可以 <code>MPI_STATUS_IGNORE</code> 了。</li>
</ul>
</li>
</ul>
<h3 id="duo-jin-cheng-tong-bu">多进程同步</h3>
<ul>
<li>
<p>使用 <code>MPI_Barrier(MPI_Comm communicator)</code> 来同步进程</p>
<ul>
<li>必须所有进程都执行到这一句才会继续执行下去，否则整个程序会卡住</li>
</ul>
</li>
<li>
<p>使用 <code>MPI_Bcast(const void *buf, int count, MPI_Datatype datatype, int root, MPI_Comm comm)</code> 来广播 / 接受广播数据。</p>
<ul>
<li>如果自己的进程编号是 root，则发送 <code>buf</code>，否则接收</li>
<li><code>MPI_Bcast</code> 使用一种树形广播算法来实现高效地广播
<ul>
<li>简单的测试表明在单机的多个核上（即不涉及网络通信），<code>MPI_Bcast</code> 的效率大概是朴素的线性实现的 $\log N$ 倍，即 2 线程性能一致、4 线程性能 2 倍，8 线程性能 3 倍...</li>
<li>它的广播行为和网络拓扑是否有关？换言之，对于异构集群，它是否会找比较“好”的广播路径？</li>
</ul>
</li>
</ul>
</li>
<li>
<p>使用 <code>MPI_Scatter(void* send_data, int send_count, MPI_Datatype send_datatype, void* recv_data, int recv_count, MPI_Datatype recv_datatype, int root, MPI_Comm communicator)</code> 来将一个缓冲区内的数据切分并将各段发送至其他进程。</p>
<ul>
<li><code>send_data</code> 是发送缓冲区</li>
<li><code>send_count</code> 是待发送元素个数</li>
<li><code>send_datatype</code> 是待发送元素类型</li>
<li><code>recv_data</code> 是接收缓冲区</li>
<li><code>recv_count</code> 是接收元素个数
<ul>
<li>一般而言应当是 <code>send_count</code> 的约数</li>
</ul>
</li>
<li><code>recv_datatype</code> 是待接收元素类型
<ul>
<li>一般和发送保持一致就可以了</li>
</ul>
</li>
<li><code>root</code> 是发送进程</li>
<li><code>communicator</code> 是组通讯器</li>
</ul>
</li>
</ul>
<div class="side-by-side-container"><img alt="Bcast vs Scatter" id="should-invert" src="/images/mpi-reference/broadcastvsscatter.webp"></div>
<ul>
<li>使用 <code>MPI_Gather(void* send_data, int send_count, MPI_Datatype send_datatype, void* recv_data, int recv_count, MPI_Datatype recv_datatype, int root, MPI_Comm communicator)</code> 来将各进程内的数据接收至 root 进程的一个大缓冲区内，与 <code>MPI_Scatter</code> 正好相反。由于函数签名一致，参数也不赘述了。</li>
</ul>
<div class="side-by-side-container"><img alt="Gather" id="should-invert" src="/images/mpi-reference/gather.webp"/></div>
<ul>
<li>
<p>一个常见工作方式是这样的</p>
<ul>
<li>0 号 process 是 root process，其他为 worker process</li>
<li>root 准备好数据后将数据 Scatter 到各个 worker process 上去，由 worker 执行操作</li>
<li>用 Barrier 保证所有 worker 操作都执行完毕</li>
<li>root 再将所有数据 Gather 回来</li>
<li>感觉这其实和 Map 很像XD</li>
</ul>
</li>
<li>
<p>使用 <code>MPI_Allgather(void* send_data, int send_count, MPI_Datatype send_datatype, void* recv_data, int recv_count, MPI_Datatype recv_datatype, MPI_Comm communicator)</code> 来实现先 Gather 再 Bcast 的操作，即完成后所有 process 的缓冲区中都是相同的副本。除去没有 root（也不需要了）以外，函数签名和 <code>MPI_Gather</code> 一致，不再赘述。</p>
</li>
</ul>
<div class="side-by-side-container"><img alt="Allgather" id="should-invert" src="/images/mpi-reference/allgather.webp"/></div>
<ul>
<li>使用 <code>MPI_Reduce(void* send_data, void* recv_data, int count, MPI_Datatype datatype, MPI_Op op, int root, MPI_Comm communicator)</code> 来进行多进程数据的 reduce 操作。
<ul>
<li><code>send_data</code> 是各个进程待 reduce 的发送缓冲区</li>
<li><code>recv_data</code> 是 root 进程存放 reduce 结果的接收缓冲区</li>
<li><code>count</code> 是缓冲区中元素个数</li>
<li><code>datatype</code> 是元素类型</li>
<li><code>op</code> 是 MPI 预先定义的 reduce 操作，包括最大/最小值、求和/求积、按位与/或、最大/最小值所在 rank 等。</li>
<li><code>root</code> 是接收 reduce 结果的根进程</li>
<li><code>communicator</code> 是通讯器</li>
</ul>
</li>
</ul>
<div class="side-by-side-container"><img alt="count = 1 的 reduce" id="should-invert" src="/images/mpi-reference/mpi_reduce_1.webp"/></div>
<div class="side-by-side-container"><img alt="count = 2 的 reduce" id="should-invert" src="/images/mpi-reference/mpi_reduce_2.webp"/></div>
<ul>
<li><code>MPI_Allreduce</code> 和 <code>MPI_reduce</code> 的关系类似前面的 Allgather 和 gather，它将 reduce 后的数据发送给所有进程，因此签名为 <code>MPI_Allreduce(void* send_data, void* recv_data, int count, MPI_Datatype datatype, MPI_Op op, MPI_Comm communicator)</code>，没有 root，其余不变。</li>
</ul>
<div class="side-by-side-container"><img alt="Allreduce" id="should-invert" src="/images/mpi-reference/mpi_allreduce_1.webp"/></div>
<h3 id="tong-xun-qi-yu-zu">通讯器与组</h3>
<ul>
<li>
<p>一个“组”可以视为一个 process 的集合</p>
</li>
<li>
<p>一个通讯器对应一个组，用于组内 process 的相互通信</p>
<ul>
<li><code>MPI_COMM_WORLD</code> 是包含所有 process 的全局通讯器</li>
<li>使用 <code>MPI_Comm_Rank(MPI_Comm comm, int *rank)</code> 来获取自己在通讯器内的 rank</li>
<li>使用 <code>MPI_Comm_Size(MPI_Comm comm, int *size)</code> 来获取这个通讯器中的线程数</li>
</ul>
</li>
<li>
<p>使用 <code>MPI_Comm_split(MPI_Comm comm, int color, int key, MPI_Comm* newcomm)</code> 来分割旧的 Communicator，创建新的</p>
<ul>
<li><code>comm</code> 是旧的通讯器</li>
<li><code>color</code> 相同的进程会被分到同一个组（也即同一个新通讯器）内</li>
<li><code>rank</code> 的顺序会被用于确定新的组内的 rank</li>
<li><code>new_comm</code> 是新创建的通讯器</li>
</ul>
</li>
</ul>
<p>例如，用 16 个 process 运行以下代码（只保留核心部分）：</p>
<pre data-lang="c" style="background-color:#2b303b;color:#c0c5ce;" class="language-c "><code class="language-c" data-lang="c"><span style="color:#b48ead;">int</span><span> world_rank, world_size;
</span><span style="color:#bf616a;">MPI_Comm_rank</span><span>(MPI_COMM_WORLD, &amp;world_rank);
</span><span style="color:#bf616a;">MPI_Comm_size</span><span>(MPI_COMM_WORLD, &amp;world_size);
</span><span>
</span><span style="color:#b48ead;">int</span><span> color = world_rank / </span><span style="color:#d08770;">4</span><span>;
</span><span>
</span><span>MPI_Comm row_comm;
</span><span style="color:#bf616a;">MPI_Comm_split</span><span>(MPI_COMM_WORLD, color, world_rank, &amp;row_comm);
</span><span>
</span><span style="color:#b48ead;">int</span><span> row_rank, row_size;
</span><span style="color:#bf616a;">MPI_Comm_rank</span><span>(row_comm, &amp;row_rank);
</span><span style="color:#bf616a;">MPI_Comm_size</span><span>(row_comm, &amp;row_size);
</span><span>
</span><span style="color:#bf616a;">printf</span><span>(&quot;</span><span style="color:#a3be8c;">World rank &amp; size: </span><span style="color:#d08770;">%d</span><span style="color:#a3be8c;"> / </span><span style="color:#d08770;">%d</span><span style="color:#96b5b4;">\t</span><span>&quot;, world_rank, world_size);
</span><span style="color:#bf616a;">printf</span><span>(&quot;</span><span style="color:#a3be8c;">Row rank &amp; size: </span><span style="color:#d08770;">%d</span><span style="color:#a3be8c;"> / </span><span style="color:#d08770;">%d</span><span style="color:#96b5b4;">\n</span><span>&quot;, row_rank, row_size);
</span></code></pre>
<p>原本是 <code>(world_rank, 16)</code> 的 process 在新的通讯器中会变为 <code>(world_rank / 4, 16)</code></p>
<div class="side-by-side-container"><img alt="MPI_Comm_split" id="should-invert" src="/images/mpi-reference/comm_split.webp"/></div>
<p>如果将 <code>world_rank / 4</code> 改为 <code>world_rank % 4</code> 那么将会由横向划分变为纵向划分，原理类似。</p>
<ul>
<li>
<p>使用 <code>MPI_Comm_create(MPI_Comm comm, MPI_Group group, MPI_Comm *newcomm)</code> 和 <code>MPI_Comm_create_group(MPI_Comm comm, MPI_Group group, int tag, MPI_Comm *newcomm)</code> 都可以由一个组创建新的通讯器。</p>
<ul>
<li>没有很明白区别</li>
</ul>
</li>
<li>
<p><code>MPI_Group</code> 可以执行交、并等集合运算</p>
</li>
</ul>
<p>实话说，教程里这部分过于简略，基本上没看懂。</p>
<p>听去年选课的同学说，课上实际使用 MPI 的时候，一般不需要分组创建通讯器，只需要 <code>MPI_COMM_WORLD</code> 一把梭即可，所以这里也不再深究了。</p>
<h3 id="za-xiang">杂项</h3>
<ul>
<li>使用 <code>MPI_Wtime()</code> 计时
<ul>
<li>返回 1970-1-1 到现在为止的秒数，也即 UNIX 时间戳</li>
</ul>
</li>
</ul>

</main>

    <div class="dark-mode-buttons">
        <button class="dark-mode-button" id="dark-mode-on"><img src="https://blog.zcy.moe/dark_mode.svg" width="24" height="24" alt=""></button>
        <button class="dark-mode-button" id="dark-mode-off"><img src="https://blog.zcy.moe/light_mode.svg" width="24" height="24" alt=""></button>
    </div>
    <div class="language-switch-buttons">
        <button class="language-switch-button" id="language-switch-dark-on"><img src="https://blog.zcy.moe/translation_dark.svg" width="24" height="24" alt=""></button>
        <button class="language-switch-button" id="language-switch-dark-off"><img src="https://blog.zcy.moe/translation_light.svg" width="24" height="24" alt=""></button>
        <ul class="language-dropdown">
            <li class="language-option" id="switch-to-en">English</li>
            <li class="language-option" id="switch-to-zh-cn">中文</li>
        </ul>
    </div>
    <div id="action-botton">
        <div class="action-wrapper">
            <div class="action meter">
                <span id="progress_meter">JS</span>
            </div>
            <a href="#top" class="action up no-dot">
                <svg xmlns='http://www.w3.org/2000/svg' class='icon' viewBox='0 0 512 512'><title>Arrow Up</title><path fill='none' stroke='currentColor' stroke-linecap='square' stroke-miterlimit='10' stroke-width='48' d='M112 244l144-144 144 144M256 120v292'/></svg>
            </a>
        </div>
    </div>
    <!-- JS for light/dark switch, minified -->
    <script>const cls=document.body.classList;const getSessionTheme=sessionStorage.getItem("theme");if(getSessionTheme==="dark"){cls.toggle("dark-mode",true)}else if(getSessionTheme==="light"){cls.toggle("dark-mode",false)}else if(window.matchMedia("(prefers-color-scheme: dark)").matches){cls.toggle("dark-mode",true)}document.getElementById("dark-mode-on").addEventListener("click",function(e){cls.toggle("dark-mode",true);sessionStorage.setItem("theme","dark")});document.getElementById("dark-mode-off").addEventListener("click",function(e){cls.toggle("dark-mode",false);sessionStorage.setItem("theme","light")});</script>
    <!-- JS for progress meter, minified -->
    <script type="text/javascript">let progress_meter=document.getElementById("progress_meter"),height=document.body.scrollHeight-screen.height,last_position=window.scrollY;function update_progress_meter(){height=document.body.clientHeight-window.innerHeight,current_position=window.scrollY,progress=Math.ceil(current_position/height*100),height==0?progress=100:progress<0?progress=0:progress>100&&(progress=100),progress_meter.innerText=(progress==100?"End":(progress+"%"))}let ticking=!1;window.addEventListener('scroll',function(a){ticking||(window.requestAnimationFrame(function(){update_progress_meter(),ticking=!1}),ticking=!0)}),progress_meter.style.textDecoration='none',update_progress_meter()</script>
    <!-- JS for language toggle, minified -->
    <script type="text/javascript">let toggle_language=function(lang_code){return function(){const currentUrl=window.location.href;const url=new URL(currentUrl);const path=url.pathname;if(!path.startsWith(`/${ lang_code }`)){const newPath=`/${ lang_code }${ path }`;const newUrl=`${url.origin }${ newPath }${url.search }${url.hash }`;window.location.href=newUrl}}};let toggle_default_language=function(){const currentUrl=window.location.href;const url=new URL(currentUrl);const path=url.pathname;const possible_lang_codes=['en'];const lang_code=path.split("/")[1];if(possible_lang_codes.includes(lang_code)){const newPath=path.replace(`/${ lang_code }`,'');const newUrl=`${url.origin }${ newPath }${url.search }${url.hash }`;window.location.href=newUrl}};document.getElementById('switch-to-en').addEventListener('click',toggle_language('en'));document.getElementById('switch-to-zh-cn').addEventListener('click',toggle_default_language);</script>
    <noscript>
        <style>
            .dark-mode-buttons {
                display: none;
            }
        </style>
    </noscript>
</body>
</html>
